{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V_1_cell_counting_ConvNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrMuG28z_oSz",
        "colab_type": "code",
        "outputId": "733f6261-5da3-413e-9c7b-286edd88bb3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRUSLuQFuvCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp /content/drive/My\\ Drive/EDF_norm.zip /content/\n",
        "! cp /content/drive/My\\ Drive/output_frame_cells_count.csv /content/\n",
        "\n",
        "# # !rm 'EDF_norm.zip'\n",
        "# # !ls /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu9njUQeu149",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip EDF_norm.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jHUNS_o7yXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/EDF_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PACewLsePM2",
        "colab_type": "code",
        "outputId": "f1452bf2-f3fa-424f-de9c-941cb81c5db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import pathlib\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "#from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J-sKTB2ePM6",
        "colab_type": "code",
        "outputId": "2e6c663e-a2c3-435d-ba47-8aec852719e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = \"/content/EDF_norm/\"\n",
        "files = os.listdir(path)\n",
        "files = sorted([file for file in files if \".png\" in file])\n",
        "X = np.zeros(shape=(len(files), 800, 800, 1), dtype=np.float16)\n",
        "for index, file in enumerate(files):\n",
        "  image = io.imread(os.path.join(path, file))\n",
        "  image = image / np.max(image)\n",
        "  X[index, :, :, 0] = image\n",
        "\n",
        "# X = np.array([ np.array(io.imread(path + fname)) for fname in files])\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(93, 800, 800, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAVc0sovePM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = np.reshape(X, (93, 800,800,1))\n",
        "# X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6BZGOmDePNC",
        "colab_type": "code",
        "outputId": "01ec6ec6-5831-4a57-d06a-2fbc060829dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.read_csv('/content/output_frame_cells_count.csv')\n",
        "Y = df['count'].values\n",
        "Y.shape # type(Y)= numpy.ndarray"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKAZ2J-ePNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# increase dimension by 1\n",
        "\n",
        "#option to shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qnhC_lRePNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = X[:75] # 75 images\n",
        "x_test = X[75:90] # 25 images\n",
        "\n",
        "y_train = Y[:75]\n",
        "y_test = Y[75:90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ynWjHBzePNN",
        "colab_type": "code",
        "outputId": "525963b7-2dd8-4d68-ae39-6bca88492be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "def build_model():\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu', input_shape=(800,800, 1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Flatten(), \n",
        "    keras.layers.Dense(500, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-04), loss='mean_squared_error', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# model.compile(loss='mean_squared_error', optimizer=optimizer,\n",
        "#  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 798, 798, 16)      160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 399, 399, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 399, 399, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 397, 397, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 198, 198, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 198, 198, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 196, 196, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 98, 98, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 98, 98, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 614656)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               307328500 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 501       \n",
            "=================================================================\n",
            "Total params: 307,352,297\n",
            "Trainable params: 307,352,297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMn6iYcZePNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        x, y = self.test_data\n",
        "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
        "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
        "\n",
        "        \n",
        "# model.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
        "#           callbacks=[TestCallback((X_test, Y_test))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrE4O5SMePNZ",
        "colab_type": "code",
        "outputId": "affaaf77-dddf-45a2-b4bf-2667745c5757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15167
        }
      },
      "source": [
        "EPOCHS = 3000\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=EPOCHS, \n",
        "    validation_split = 0.2,\n",
        "    verbose=2, \n",
        "    batch_size=4,\n",
        "    callbacks=[TestCallback((x_test, y_test))], \n",
        "    \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60 samples, validate on 15 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/3000\n",
            "\n",
            "Testing loss: 239.13375854492188, acc: 0.0\n",
            "\n",
            " - 116s - loss: 765.6091 - acc: 0.0000e+00 - val_loss: 1625.3924 - val_acc: 0.0000e+00\n",
            "Epoch 2/3000\n",
            "\n",
            "Testing loss: 251.15061950683594, acc: 0.0\n",
            "\n",
            " - 110s - loss: 437.6905 - acc: 0.0000e+00 - val_loss: 1645.0583 - val_acc: 0.0000e+00\n",
            "Epoch 3/3000\n",
            "\n",
            "Testing loss: 231.50466918945312, acc: 0.0\n",
            "\n",
            " - 111s - loss: 380.6628 - acc: 0.0000e+00 - val_loss: 1553.1007 - val_acc: 0.0000e+00\n",
            "Epoch 4/3000\n",
            "\n",
            "Testing loss: 198.3865203857422, acc: 0.0\n",
            "\n",
            " - 111s - loss: 319.3882 - acc: 0.0000e+00 - val_loss: 1397.8656 - val_acc: 0.0000e+00\n",
            "Epoch 5/3000\n",
            "\n",
            "Testing loss: 200.52163696289062, acc: 0.0\n",
            "\n",
            " - 110s - loss: 338.8399 - acc: 0.0000e+00 - val_loss: 1392.3913 - val_acc: 0.0000e+00\n",
            "Epoch 6/3000\n",
            "\n",
            "Testing loss: 209.8732147216797, acc: 0.0\n",
            "\n",
            " - 109s - loss: 287.0354 - acc: 0.0000e+00 - val_loss: 1415.9268 - val_acc: 0.0000e+00\n",
            "Epoch 7/3000\n",
            "\n",
            "Testing loss: 199.72201538085938, acc: 0.0\n",
            "\n",
            " - 110s - loss: 259.1994 - acc: 0.0000e+00 - val_loss: 1355.0669 - val_acc: 0.0000e+00\n",
            "Epoch 8/3000\n",
            "\n",
            "Testing loss: 247.19168090820312, acc: 0.0\n",
            "\n",
            " - 110s - loss: 247.3945 - acc: 0.0000e+00 - val_loss: 1484.0190 - val_acc: 0.0000e+00\n",
            "Epoch 9/3000\n",
            "\n",
            "Testing loss: 317.57965087890625, acc: 0.0\n",
            "\n",
            " - 110s - loss: 225.4808 - acc: 0.0000e+00 - val_loss: 1634.1867 - val_acc: 0.0000e+00\n",
            "Epoch 10/3000\n",
            "\n",
            "Testing loss: 232.62684631347656, acc: 0.0\n",
            "\n",
            " - 111s - loss: 284.5815 - acc: 0.0000e+00 - val_loss: 1417.5805 - val_acc: 0.0000e+00\n",
            "Epoch 11/3000\n",
            "\n",
            "Testing loss: 182.25352478027344, acc: 0.0\n",
            "\n",
            " - 111s - loss: 272.6835 - acc: 0.0000e+00 - val_loss: 1225.7622 - val_acc: 0.0000e+00\n",
            "Epoch 12/3000\n",
            "\n",
            "Testing loss: 219.23092651367188, acc: 0.0\n",
            "\n",
            " - 110s - loss: 249.7282 - acc: 0.0000e+00 - val_loss: 1365.0916 - val_acc: 0.0000e+00\n",
            "Epoch 13/3000\n",
            "\n",
            "Testing loss: 264.55328369140625, acc: 0.0\n",
            "\n",
            " - 109s - loss: 243.8639 - acc: 0.0000e+00 - val_loss: 1501.4229 - val_acc: 0.0000e+00\n",
            "Epoch 14/3000\n",
            "\n",
            "Testing loss: 243.71917724609375, acc: 0.0\n",
            "\n",
            " - 110s - loss: 241.6284 - acc: 0.0000e+00 - val_loss: 1450.5135 - val_acc: 0.0000e+00\n",
            "Epoch 15/3000\n",
            "\n",
            "Testing loss: 398.1084899902344, acc: 0.0\n",
            "\n",
            " - 110s - loss: 311.9961 - acc: 0.0000e+00 - val_loss: 1837.0265 - val_acc: 0.0000e+00\n",
            "Epoch 16/3000\n",
            "\n",
            "Testing loss: 335.8036804199219, acc: 0.0\n",
            "\n",
            " - 110s - loss: 290.8985 - acc: 0.0000e+00 - val_loss: 1736.3660 - val_acc: 0.0000e+00\n",
            "Epoch 17/3000\n",
            "\n",
            "Testing loss: 231.29246520996094, acc: 0.0\n",
            "\n",
            " - 110s - loss: 319.3083 - acc: 0.0000e+00 - val_loss: 1463.9512 - val_acc: 0.0000e+00\n",
            "Epoch 18/3000\n",
            "\n",
            "Testing loss: 240.66409301757812, acc: 0.0\n",
            "\n",
            " - 110s - loss: 254.1016 - acc: 0.0000e+00 - val_loss: 1483.8107 - val_acc: 0.0000e+00\n",
            "Epoch 19/3000\n",
            "\n",
            "Testing loss: 248.2932586669922, acc: 0.0\n",
            "\n",
            " - 109s - loss: 211.0563 - acc: 0.0000e+00 - val_loss: 1472.4741 - val_acc: 0.0000e+00\n",
            "Epoch 20/3000\n",
            "\n",
            "Testing loss: 242.4748992919922, acc: 0.0\n",
            "\n",
            " - 109s - loss: 179.5785 - acc: 0.0000e+00 - val_loss: 1430.6473 - val_acc: 0.0000e+00\n",
            "Epoch 21/3000\n",
            "\n",
            "Testing loss: 204.84439086914062, acc: 0.0\n",
            "\n",
            " - 110s - loss: 158.0714 - acc: 0.0000e+00 - val_loss: 1283.1342 - val_acc: 0.0000e+00\n",
            "Epoch 22/3000\n",
            "\n",
            "Testing loss: 252.6858367919922, acc: 0.0\n",
            "\n",
            " - 111s - loss: 168.5015 - acc: 0.0000e+00 - val_loss: 1417.2130 - val_acc: 0.0000e+00\n",
            "Epoch 23/3000\n",
            "\n",
            "Testing loss: 276.36090087890625, acc: 0.0\n",
            "\n",
            " - 109s - loss: 175.0119 - acc: 0.0000e+00 - val_loss: 1475.6132 - val_acc: 0.0000e+00\n",
            "Epoch 24/3000\n",
            "\n",
            "Testing loss: 211.29830932617188, acc: 0.0\n",
            "\n",
            " - 109s - loss: 152.1746 - acc: 0.0000e+00 - val_loss: 1271.3079 - val_acc: 0.0000e+00\n",
            "Epoch 25/3000\n",
            "\n",
            "Testing loss: 201.83432006835938, acc: 0.0\n",
            "\n",
            " - 109s - loss: 145.2145 - acc: 0.0000e+00 - val_loss: 1236.2719 - val_acc: 0.0000e+00\n",
            "Epoch 26/3000\n",
            "\n",
            "Testing loss: 295.13433837890625, acc: 0.0\n",
            "\n",
            " - 109s - loss: 158.3634 - acc: 0.0000e+00 - val_loss: 1488.8657 - val_acc: 0.0000e+00\n",
            "Epoch 27/3000\n",
            "\n",
            "Testing loss: 259.2896423339844, acc: 0.0\n",
            "\n",
            " - 109s - loss: 184.0962 - acc: 0.0000e+00 - val_loss: 1427.0732 - val_acc: 0.0000e+00\n",
            "Epoch 28/3000\n",
            "\n",
            "Testing loss: 298.2822265625, acc: 0.0\n",
            "\n",
            " - 109s - loss: 130.5684 - acc: 0.0000e+00 - val_loss: 1494.6749 - val_acc: 0.0000e+00\n",
            "Epoch 29/3000\n",
            "\n",
            "Testing loss: 335.0507507324219, acc: 0.0\n",
            "\n",
            " - 109s - loss: 174.7136 - acc: 0.0000e+00 - val_loss: 1605.1883 - val_acc: 0.0000e+00\n",
            "Epoch 30/3000\n",
            "\n",
            "Testing loss: 241.31040954589844, acc: 0.0\n",
            "\n",
            " - 109s - loss: 273.6870 - acc: 0.0000e+00 - val_loss: 1404.3846 - val_acc: 0.0000e+00\n",
            "Epoch 31/3000\n",
            "\n",
            "Testing loss: 237.4586639404297, acc: 0.0\n",
            "\n",
            " - 110s - loss: 149.5781 - acc: 0.0000e+00 - val_loss: 1354.3644 - val_acc: 0.0000e+00\n",
            "Epoch 32/3000\n",
            "\n",
            "Testing loss: 228.58224487304688, acc: 0.0\n",
            "\n",
            " - 109s - loss: 160.7212 - acc: 0.0000e+00 - val_loss: 1308.6566 - val_acc: 0.0000e+00\n",
            "Epoch 33/3000\n",
            "\n",
            "Testing loss: 256.2452697753906, acc: 0.0\n",
            "\n",
            " - 109s - loss: 128.7781 - acc: 0.0000e+00 - val_loss: 1384.0061 - val_acc: 0.0000e+00\n",
            "Epoch 34/3000\n",
            "\n",
            "Testing loss: 235.72174072265625, acc: 0.0\n",
            "\n",
            " - 110s - loss: 147.5995 - acc: 0.0000e+00 - val_loss: 1328.8275 - val_acc: 0.0000e+00\n",
            "Epoch 35/3000\n",
            "\n",
            "Testing loss: 237.3347625732422, acc: 0.0\n",
            "\n",
            " - 111s - loss: 112.1846 - acc: 0.0000e+00 - val_loss: 1308.6692 - val_acc: 0.0000e+00\n",
            "Epoch 36/3000\n",
            "\n",
            "Testing loss: 250.2361297607422, acc: 0.0\n",
            "\n",
            " - 111s - loss: 101.5172 - acc: 0.0000e+00 - val_loss: 1352.3207 - val_acc: 0.0000e+00\n",
            "Epoch 37/3000\n",
            "\n",
            "Testing loss: 242.88308715820312, acc: 0.0\n",
            "\n",
            " - 111s - loss: 108.5162 - acc: 0.0000e+00 - val_loss: 1319.9625 - val_acc: 0.0000e+00\n",
            "Epoch 38/3000\n",
            "\n",
            "Testing loss: 248.47637939453125, acc: 0.0\n",
            "\n",
            " - 111s - loss: 104.6821 - acc: 0.0000e+00 - val_loss: 1318.9828 - val_acc: 0.0000e+00\n",
            "Epoch 39/3000\n",
            "\n",
            "Testing loss: 215.07843017578125, acc: 0.0\n",
            "\n",
            " - 111s - loss: 149.7379 - acc: 0.0000e+00 - val_loss: 1253.0933 - val_acc: 0.0000e+00\n",
            "Epoch 40/3000\n",
            "\n",
            "Testing loss: 224.52725219726562, acc: 0.0\n",
            "\n",
            " - 111s - loss: 89.6515 - acc: 0.0000e+00 - val_loss: 1271.6435 - val_acc: 0.0000e+00\n",
            "Epoch 41/3000\n",
            "\n",
            "Testing loss: 236.187744140625, acc: 0.0\n",
            "\n",
            " - 111s - loss: 84.0158 - acc: 0.0000e+00 - val_loss: 1289.0629 - val_acc: 0.0000e+00\n",
            "Epoch 42/3000\n",
            "\n",
            "Testing loss: 269.3246154785156, acc: 0.0\n",
            "\n",
            " - 111s - loss: 123.2587 - acc: 0.0000e+00 - val_loss: 1385.6249 - val_acc: 0.0000e+00\n",
            "Epoch 43/3000\n",
            "\n",
            "Testing loss: 226.5048065185547, acc: 0.0\n",
            "\n",
            " - 110s - loss: 93.0204 - acc: 0.0000e+00 - val_loss: 1249.4149 - val_acc: 0.0000e+00\n",
            "Epoch 44/3000\n",
            "\n",
            "Testing loss: 198.39454650878906, acc: 0.0\n",
            "\n",
            " - 110s - loss: 109.0407 - acc: 0.0000e+00 - val_loss: 1202.7109 - val_acc: 0.0000e+00\n",
            "Epoch 45/3000\n",
            "\n",
            "Testing loss: 224.6515655517578, acc: 0.0\n",
            "\n",
            " - 111s - loss: 122.4443 - acc: 0.0000e+00 - val_loss: 1271.0416 - val_acc: 0.0000e+00\n",
            "Epoch 46/3000\n",
            "\n",
            "Testing loss: 237.91488647460938, acc: 0.0\n",
            "\n",
            " - 110s - loss: 78.8947 - acc: 0.0000e+00 - val_loss: 1270.4358 - val_acc: 0.0000e+00\n",
            "Epoch 47/3000\n",
            "\n",
            "Testing loss: 248.97828674316406, acc: 0.0\n",
            "\n",
            " - 110s - loss: 72.1653 - acc: 0.0000e+00 - val_loss: 1288.3420 - val_acc: 0.0000e+00\n",
            "Epoch 48/3000\n",
            "\n",
            "Testing loss: 252.721923828125, acc: 0.0\n",
            "\n",
            " - 111s - loss: 64.2215 - acc: 0.0000e+00 - val_loss: 1281.2827 - val_acc: 0.0000e+00\n",
            "Epoch 49/3000\n",
            "\n",
            "Testing loss: 219.9794158935547, acc: 0.0\n",
            "\n",
            " - 110s - loss: 85.7416 - acc: 0.0000e+00 - val_loss: 1209.4162 - val_acc: 0.0000e+00\n",
            "Epoch 50/3000\n",
            "\n",
            "Testing loss: 257.6509094238281, acc: 0.0\n",
            "\n",
            " - 111s - loss: 72.6516 - acc: 0.0000e+00 - val_loss: 1304.8704 - val_acc: 0.0000e+00\n",
            "Epoch 51/3000\n",
            "\n",
            "Testing loss: 274.17755126953125, acc: 0.0\n",
            "\n",
            " - 110s - loss: 52.0101 - acc: 0.0000e+00 - val_loss: 1341.1270 - val_acc: 0.0000e+00\n",
            "Epoch 52/3000\n",
            "\n",
            "Testing loss: 241.59530639648438, acc: 0.0\n",
            "\n",
            " - 110s - loss: 56.3819 - acc: 0.0000e+00 - val_loss: 1258.2417 - val_acc: 0.0000e+00\n",
            "Epoch 53/3000\n",
            "\n",
            "Testing loss: 299.1544494628906, acc: 0.0\n",
            "\n",
            " - 110s - loss: 59.0545 - acc: 0.0000e+00 - val_loss: 1399.5860 - val_acc: 0.0000e+00\n",
            "Epoch 54/3000\n",
            "\n",
            "Testing loss: 208.52874755859375, acc: 0.0\n",
            "\n",
            " - 109s - loss: 94.6276 - acc: 0.0000e+00 - val_loss: 1206.0971 - val_acc: 0.0000e+00\n",
            "Epoch 55/3000\n",
            "\n",
            "Testing loss: 223.75033569335938, acc: 0.0\n",
            "\n",
            " - 109s - loss: 80.7156 - acc: 0.0000e+00 - val_loss: 1220.6757 - val_acc: 0.0000e+00\n",
            "Epoch 56/3000\n",
            "\n",
            "Testing loss: 296.0033874511719, acc: 0.0\n",
            "\n",
            " - 110s - loss: 80.1932 - acc: 0.0000e+00 - val_loss: 1413.2192 - val_acc: 0.0000e+00\n",
            "Epoch 57/3000\n",
            "\n",
            "Testing loss: 227.1264190673828, acc: 0.0\n",
            "\n",
            " - 110s - loss: 72.4820 - acc: 0.0000e+00 - val_loss: 1252.8178 - val_acc: 0.0000e+00\n",
            "Epoch 58/3000\n",
            "\n",
            "Testing loss: 260.5784606933594, acc: 0.0\n",
            "\n",
            " - 109s - loss: 43.6676 - acc: 0.0000e+00 - val_loss: 1296.5601 - val_acc: 0.0000e+00\n",
            "Epoch 59/3000\n",
            "\n",
            "Testing loss: 237.74781799316406, acc: 0.0\n",
            "\n",
            " - 110s - loss: 44.6033 - acc: 0.0000e+00 - val_loss: 1229.5237 - val_acc: 0.0000e+00\n",
            "Epoch 60/3000\n",
            "\n",
            "Testing loss: 282.6685485839844, acc: 0.0\n",
            "\n",
            " - 109s - loss: 44.1865 - acc: 0.0000e+00 - val_loss: 1341.1896 - val_acc: 0.0000e+00\n",
            "Epoch 61/3000\n",
            "\n",
            "Testing loss: 223.5663299560547, acc: 0.0\n",
            "\n",
            " - 110s - loss: 75.9685 - acc: 0.0000e+00 - val_loss: 1223.7563 - val_acc: 0.0000e+00\n",
            "Epoch 62/3000\n",
            "\n",
            "Testing loss: 292.24639892578125, acc: 0.0\n",
            "\n",
            " - 110s - loss: 66.4338 - acc: 0.0000e+00 - val_loss: 1372.0243 - val_acc: 0.0000e+00\n",
            "Epoch 63/3000\n",
            "\n",
            "Testing loss: 217.49118041992188, acc: 0.0\n",
            "\n",
            " - 110s - loss: 71.1221 - acc: 0.0000e+00 - val_loss: 1223.0985 - val_acc: 0.0000e+00\n",
            "Epoch 64/3000\n",
            "\n",
            "Testing loss: 270.2662048339844, acc: 0.0\n",
            "\n",
            " - 109s - loss: 60.3250 - acc: 0.0000e+00 - val_loss: 1323.9991 - val_acc: 0.0000e+00\n",
            "Epoch 65/3000\n",
            "\n",
            "Testing loss: 252.3264923095703, acc: 0.0\n",
            "\n",
            " - 110s - loss: 51.1891 - acc: 0.0000e+00 - val_loss: 1283.5032 - val_acc: 0.0000e+00\n",
            "Epoch 66/3000\n",
            "\n",
            "Testing loss: 239.13294982910156, acc: 0.0\n",
            "\n",
            " - 111s - loss: 35.3438 - acc: 0.0000e+00 - val_loss: 1209.9791 - val_acc: 0.0000e+00\n",
            "Epoch 67/3000\n",
            "\n",
            "Testing loss: 258.8154602050781, acc: 0.0\n",
            "\n",
            " - 111s - loss: 32.7136 - acc: 0.0000e+00 - val_loss: 1274.6556 - val_acc: 0.0000e+00\n",
            "Epoch 68/3000\n",
            "\n",
            "Testing loss: 276.4306640625, acc: 0.0\n",
            "\n",
            " - 113s - loss: 55.4562 - acc: 0.0000e+00 - val_loss: 1316.0048 - val_acc: 0.0000e+00\n",
            "Epoch 69/3000\n",
            "\n",
            "Testing loss: 223.93612670898438, acc: 0.0\n",
            "\n",
            " - 117s - loss: 57.9513 - acc: 0.0000e+00 - val_loss: 1217.1535 - val_acc: 0.0000e+00\n",
            "Epoch 70/3000\n",
            "\n",
            "Testing loss: 288.5482482910156, acc: 0.0\n",
            "\n",
            " - 114s - loss: 36.3573 - acc: 0.0000e+00 - val_loss: 1336.5829 - val_acc: 0.0000e+00\n",
            "Epoch 71/3000\n",
            "\n",
            "Testing loss: 226.36935424804688, acc: 0.0\n",
            "\n",
            " - 114s - loss: 31.0615 - acc: 0.0000e+00 - val_loss: 1187.7403 - val_acc: 0.0000e+00\n",
            "Epoch 72/3000\n",
            "\n",
            "Testing loss: 282.5638122558594, acc: 0.0\n",
            "\n",
            " - 114s - loss: 37.4465 - acc: 0.0000e+00 - val_loss: 1310.0991 - val_acc: 0.0000e+00\n",
            "Epoch 73/3000\n",
            "\n",
            "Testing loss: 280.8316345214844, acc: 0.0\n",
            "\n",
            " - 114s - loss: 20.7608 - acc: 0.0000e+00 - val_loss: 1290.4828 - val_acc: 0.0000e+00\n",
            "Epoch 74/3000\n",
            "\n",
            "Testing loss: 317.4664306640625, acc: 0.0\n",
            "\n",
            " - 114s - loss: 20.3271 - acc: 0.0000e+00 - val_loss: 1342.1984 - val_acc: 0.0000e+00\n",
            "Epoch 75/3000\n",
            "\n",
            "Testing loss: 292.6607971191406, acc: 0.0\n",
            "\n",
            " - 114s - loss: 37.8220 - acc: 0.0000e+00 - val_loss: 1305.1443 - val_acc: 0.0000e+00\n",
            "Epoch 76/3000\n",
            "\n",
            "Testing loss: 247.24221801757812, acc: 0.0\n",
            "\n",
            " - 113s - loss: 29.0797 - acc: 0.0000e+00 - val_loss: 1235.8235 - val_acc: 0.0000e+00\n",
            "Epoch 77/3000\n",
            "\n",
            "Testing loss: 304.4189453125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 50.5727 - acc: 0.0000e+00 - val_loss: 1366.4788 - val_acc: 0.0000e+00\n",
            "Epoch 78/3000\n",
            "\n",
            "Testing loss: 267.5694580078125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 21.2114 - acc: 0.0000e+00 - val_loss: 1268.8447 - val_acc: 0.0000e+00\n",
            "Epoch 79/3000\n",
            "\n",
            "Testing loss: 289.3272399902344, acc: 0.0\n",
            "\n",
            " - 113s - loss: 19.0269 - acc: 0.0000e+00 - val_loss: 1309.1230 - val_acc: 0.0000e+00\n",
            "Epoch 80/3000\n",
            "\n",
            "Testing loss: 270.53350830078125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 20.5002 - acc: 0.0000e+00 - val_loss: 1258.6657 - val_acc: 0.0000e+00\n",
            "Epoch 81/3000\n",
            "\n",
            "Testing loss: 282.5729675292969, acc: 0.0\n",
            "\n",
            " - 112s - loss: 18.3436 - acc: 0.0000e+00 - val_loss: 1288.9183 - val_acc: 0.0000e+00\n",
            "Epoch 82/3000\n",
            "\n",
            "Testing loss: 293.5484619140625, acc: 0.0\n",
            "\n",
            " - 112s - loss: 10.6307 - acc: 0.0000e+00 - val_loss: 1292.0721 - val_acc: 0.0000e+00\n",
            "Epoch 83/3000\n",
            "\n",
            "Testing loss: 285.5939025878906, acc: 0.0\n",
            "\n",
            " - 113s - loss: 12.4357 - acc: 0.0000e+00 - val_loss: 1268.9990 - val_acc: 0.0000e+00\n",
            "Epoch 84/3000\n",
            "\n",
            "Testing loss: 302.0999450683594, acc: 0.0\n",
            "\n",
            " - 113s - loss: 11.6594 - acc: 0.0000e+00 - val_loss: 1307.0804 - val_acc: 0.0000e+00\n",
            "Epoch 85/3000\n",
            "\n",
            "Testing loss: 289.0173034667969, acc: 0.0\n",
            "\n",
            " - 113s - loss: 13.8653 - acc: 0.0000e+00 - val_loss: 1266.8135 - val_acc: 0.0000e+00\n",
            "Epoch 86/3000\n",
            "\n",
            "Testing loss: 301.0711669921875, acc: 0.0\n",
            "\n",
            " - 113s - loss: 11.9207 - acc: 0.0000e+00 - val_loss: 1306.1898 - val_acc: 0.0000e+00\n",
            "Epoch 87/3000\n",
            "\n",
            "Testing loss: 278.79888916015625, acc: 0.0\n",
            "\n",
            " - 113s - loss: 18.1608 - acc: 0.0000e+00 - val_loss: 1282.4430 - val_acc: 0.0000e+00\n",
            "Epoch 88/3000\n",
            "\n",
            "Testing loss: 280.86614990234375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 21.5484 - acc: 0.0000e+00 - val_loss: 1291.2450 - val_acc: 0.0000e+00\n",
            "Epoch 89/3000\n",
            "\n",
            "Testing loss: 301.8618469238281, acc: 0.0\n",
            "\n",
            " - 114s - loss: 16.9054 - acc: 0.0000e+00 - val_loss: 1308.6167 - val_acc: 0.0000e+00\n",
            "Epoch 90/3000\n",
            "\n",
            "Testing loss: 265.5806884765625, acc: 0.0\n",
            "\n",
            " - 113s - loss: 19.7169 - acc: 0.0000e+00 - val_loss: 1199.6566 - val_acc: 0.0000e+00\n",
            "Epoch 91/3000\n",
            "\n",
            "Testing loss: 312.42816162109375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 17.1481 - acc: 0.0000e+00 - val_loss: 1338.1895 - val_acc: 0.0000e+00\n",
            "Epoch 92/3000\n",
            "\n",
            "Testing loss: 279.1407470703125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 16.7047 - acc: 0.0000e+00 - val_loss: 1242.0747 - val_acc: 0.0000e+00\n",
            "Epoch 93/3000\n",
            "\n",
            "Testing loss: 314.36004638671875, acc: 0.0\n",
            "\n",
            " - 113s - loss: 11.6741 - acc: 0.0000e+00 - val_loss: 1282.4601 - val_acc: 0.0000e+00\n",
            "Epoch 94/3000\n",
            "\n",
            "Testing loss: 305.41998291015625, acc: 0.0\n",
            "\n",
            " - 112s - loss: 8.5893 - acc: 0.0000e+00 - val_loss: 1312.0132 - val_acc: 0.0000e+00\n",
            "Epoch 95/3000\n",
            "\n",
            "Testing loss: 291.69097900390625, acc: 0.0\n",
            "\n",
            " - 113s - loss: 8.4779 - acc: 0.0000e+00 - val_loss: 1275.8277 - val_acc: 0.0000e+00\n",
            "Epoch 96/3000\n",
            "\n",
            "Testing loss: 290.0138854980469, acc: 0.0\n",
            "\n",
            " - 112s - loss: 8.0258 - acc: 0.0000e+00 - val_loss: 1275.6079 - val_acc: 0.0000e+00\n",
            "Epoch 97/3000\n",
            "\n",
            "Testing loss: 308.4359130859375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 9.6369 - acc: 0.0000e+00 - val_loss: 1317.8757 - val_acc: 0.0000e+00\n",
            "Epoch 98/3000\n",
            "\n",
            "Testing loss: 276.3115234375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 11.3429 - acc: 0.0000e+00 - val_loss: 1237.9537 - val_acc: 0.0000e+00\n",
            "Epoch 99/3000\n",
            "\n",
            "Testing loss: 319.8548278808594, acc: 0.0\n",
            "\n",
            " - 114s - loss: 7.6476 - acc: 0.0000e+00 - val_loss: 1309.6083 - val_acc: 0.0000e+00\n",
            "Epoch 100/3000\n",
            "\n",
            "Testing loss: 305.4469299316406, acc: 0.0\n",
            "\n",
            " - 113s - loss: 16.7932 - acc: 0.0000e+00 - val_loss: 1290.6827 - val_acc: 0.0000e+00\n",
            "Epoch 101/3000\n",
            "\n",
            "Testing loss: 267.07427978515625, acc: 0.0\n",
            "\n",
            " - 113s - loss: 13.8700 - acc: 0.0000e+00 - val_loss: 1230.8645 - val_acc: 0.0000e+00\n",
            "Epoch 102/3000\n",
            "\n",
            "Testing loss: 303.30438232421875, acc: 0.0\n",
            "\n",
            " - 112s - loss: 7.9956 - acc: 0.0000e+00 - val_loss: 1270.6915 - val_acc: 0.0000e+00\n",
            "Epoch 103/3000\n",
            "\n",
            "Testing loss: 308.7381896972656, acc: 0.0\n",
            "\n",
            " - 113s - loss: 15.5098 - acc: 0.0000e+00 - val_loss: 1291.7803 - val_acc: 0.0000e+00\n",
            "Epoch 104/3000\n",
            "\n",
            "Testing loss: 287.6141052246094, acc: 0.0\n",
            "\n",
            " - 113s - loss: 11.0108 - acc: 0.0000e+00 - val_loss: 1253.4452 - val_acc: 0.0000e+00\n",
            "Epoch 105/3000\n",
            "\n",
            "Testing loss: 302.8785705566406, acc: 0.0\n",
            "\n",
            " - 113s - loss: 4.7985 - acc: 0.0000e+00 - val_loss: 1279.0579 - val_acc: 0.0000e+00\n",
            "Epoch 106/3000\n",
            "\n",
            "Testing loss: 294.8050231933594, acc: 0.0\n",
            "\n",
            " - 113s - loss: 8.9908 - acc: 0.0000e+00 - val_loss: 1275.7593 - val_acc: 0.0000e+00\n",
            "Epoch 107/3000\n",
            "\n",
            "Testing loss: 285.9101867675781, acc: 0.0\n",
            "\n",
            " - 112s - loss: 8.2339 - acc: 0.0000e+00 - val_loss: 1250.4664 - val_acc: 0.0000e+00\n",
            "Epoch 108/3000\n",
            "\n",
            "Testing loss: 321.1037902832031, acc: 0.0\n",
            "\n",
            " - 112s - loss: 7.6649 - acc: 0.0000e+00 - val_loss: 1308.8716 - val_acc: 0.0000e+00\n",
            "Epoch 109/3000\n",
            "\n",
            "Testing loss: 283.9942932128906, acc: 0.0\n",
            "\n",
            " - 112s - loss: 10.6818 - acc: 0.0000e+00 - val_loss: 1228.5179 - val_acc: 0.0000e+00\n",
            "Epoch 110/3000\n",
            "\n",
            "Testing loss: 277.94866943359375, acc: 0.0\n",
            "\n",
            " - 112s - loss: 10.5716 - acc: 0.0000e+00 - val_loss: 1229.5989 - val_acc: 0.0000e+00\n",
            "Epoch 111/3000\n",
            "\n",
            "Testing loss: 291.04364013671875, acc: 0.0\n",
            "\n",
            " - 112s - loss: 4.8538 - acc: 0.0000e+00 - val_loss: 1258.4733 - val_acc: 0.0000e+00\n",
            "Epoch 112/3000\n",
            "\n",
            "Testing loss: 280.8800964355469, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.9624 - acc: 0.0000e+00 - val_loss: 1225.7804 - val_acc: 0.0000e+00\n",
            "Epoch 113/3000\n",
            "\n",
            "Testing loss: 304.1690368652344, acc: 0.0\n",
            "\n",
            " - 112s - loss: 7.5810 - acc: 0.0000e+00 - val_loss: 1262.0563 - val_acc: 0.0000e+00\n",
            "Epoch 114/3000\n",
            "\n",
            "Testing loss: 302.71661376953125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 6.5076 - acc: 0.0000e+00 - val_loss: 1278.3568 - val_acc: 0.0000e+00\n",
            "Epoch 115/3000\n",
            "\n",
            "Testing loss: 283.4324951171875, acc: 0.0\n",
            "\n",
            " - 114s - loss: 7.1659 - acc: 0.0000e+00 - val_loss: 1227.8938 - val_acc: 0.0000e+00\n",
            "Epoch 116/3000\n",
            "\n",
            "Testing loss: 283.0806884765625, acc: 0.0\n",
            "\n",
            " - 114s - loss: 9.3874 - acc: 0.0000e+00 - val_loss: 1234.6273 - val_acc: 0.0000e+00\n",
            "Epoch 117/3000\n",
            "\n",
            "Testing loss: 275.8279113769531, acc: 0.0\n",
            "\n",
            " - 114s - loss: 5.0329 - acc: 0.0000e+00 - val_loss: 1225.8717 - val_acc: 0.0000e+00\n",
            "Epoch 118/3000\n",
            "\n",
            "Testing loss: 294.65606689453125, acc: 0.0\n",
            "\n",
            " - 112s - loss: 6.4537 - acc: 0.0000e+00 - val_loss: 1235.2905 - val_acc: 0.0000e+00\n",
            "Epoch 119/3000\n",
            "\n",
            "Testing loss: 302.1171875, acc: 0.0\n",
            "\n",
            " - 112s - loss: 4.2875 - acc: 0.0000e+00 - val_loss: 1250.5199 - val_acc: 0.0000e+00\n",
            "Epoch 120/3000\n",
            "\n",
            "Testing loss: 287.2641906738281, acc: 0.0\n",
            "\n",
            " - 112s - loss: 3.7769 - acc: 0.0000e+00 - val_loss: 1236.7224 - val_acc: 0.0000e+00\n",
            "Epoch 121/3000\n",
            "\n",
            "Testing loss: 307.3824462890625, acc: 0.0\n",
            "\n",
            " - 112s - loss: 3.1310 - acc: 0.0000e+00 - val_loss: 1259.3123 - val_acc: 0.0000e+00\n",
            "Epoch 122/3000\n",
            "\n",
            "Testing loss: 295.4092102050781, acc: 0.0\n",
            "\n",
            " - 113s - loss: 6.2304 - acc: 0.0000e+00 - val_loss: 1247.4608 - val_acc: 0.0000e+00\n",
            "Epoch 123/3000\n",
            "\n",
            "Testing loss: 299.5234680175781, acc: 0.0\n",
            "\n",
            " - 113s - loss: 9.6549 - acc: 0.0000e+00 - val_loss: 1241.8826 - val_acc: 0.0000e+00\n",
            "Epoch 124/3000\n",
            "\n",
            "Testing loss: 293.2637634277344, acc: 0.0\n",
            "\n",
            " - 113s - loss: 4.2039 - acc: 0.0000e+00 - val_loss: 1256.7602 - val_acc: 0.0000e+00\n",
            "Epoch 125/3000\n",
            "\n",
            "Testing loss: 297.6976623535156, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.9205 - acc: 0.0000e+00 - val_loss: 1258.8344 - val_acc: 0.0000e+00\n",
            "Epoch 126/3000\n",
            "\n",
            "Testing loss: 310.2173767089844, acc: 0.0\n",
            "\n",
            " - 112s - loss: 3.4493 - acc: 0.0000e+00 - val_loss: 1270.9685 - val_acc: 0.0000e+00\n",
            "Epoch 127/3000\n",
            "\n",
            "Testing loss: 283.6060485839844, acc: 0.0\n",
            "\n",
            " - 112s - loss: 6.3205 - acc: 0.0000e+00 - val_loss: 1236.3824 - val_acc: 0.0000e+00\n",
            "Epoch 128/3000\n",
            "\n",
            "Testing loss: 284.89306640625, acc: 0.0\n",
            "\n",
            " - 113s - loss: 6.4333 - acc: 0.0000e+00 - val_loss: 1233.5025 - val_acc: 0.0000e+00\n",
            "Epoch 129/3000\n",
            "\n",
            "Testing loss: 286.0867004394531, acc: 0.0\n",
            "\n",
            " - 113s - loss: 5.1990 - acc: 0.0000e+00 - val_loss: 1239.1054 - val_acc: 0.0000e+00\n",
            "Epoch 130/3000\n",
            "\n",
            "Testing loss: 295.92010498046875, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.6765 - acc: 0.0000e+00 - val_loss: 1234.5227 - val_acc: 0.0000e+00\n",
            "Epoch 131/3000\n",
            "\n",
            "Testing loss: 307.02099609375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 4.1460 - acc: 0.0000e+00 - val_loss: 1262.4730 - val_acc: 0.0000e+00\n",
            "Epoch 132/3000\n",
            "\n",
            "Testing loss: 293.00396728515625, acc: 0.0\n",
            "\n",
            " - 113s - loss: 4.6157 - acc: 0.0000e+00 - val_loss: 1220.3647 - val_acc: 0.0000e+00\n",
            "Epoch 133/3000\n",
            "\n",
            "Testing loss: 300.44281005859375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 4.6989 - acc: 0.0000e+00 - val_loss: 1254.4036 - val_acc: 0.0000e+00\n",
            "Epoch 134/3000\n",
            "\n",
            "Testing loss: 320.8304443359375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 6.8265 - acc: 0.0000e+00 - val_loss: 1307.0455 - val_acc: 0.0000e+00\n",
            "Epoch 135/3000\n",
            "\n",
            "Testing loss: 279.47869873046875, acc: 0.0\n",
            "\n",
            " - 112s - loss: 7.2238 - acc: 0.0000e+00 - val_loss: 1221.1532 - val_acc: 0.0000e+00\n",
            "Epoch 136/3000\n",
            "\n",
            "Testing loss: 285.45709228515625, acc: 0.0\n",
            "\n",
            " - 112s - loss: 3.7643 - acc: 0.0000e+00 - val_loss: 1229.2559 - val_acc: 0.0000e+00\n",
            "Epoch 137/3000\n",
            "\n",
            "Testing loss: 269.7855224609375, acc: 0.0\n",
            "\n",
            " - 112s - loss: 6.0044 - acc: 0.0000e+00 - val_loss: 1226.5386 - val_acc: 0.0000e+00\n",
            "Epoch 138/3000\n",
            "\n",
            "Testing loss: 268.37109375, acc: 0.0\n",
            "\n",
            " - 112s - loss: 8.7021 - acc: 0.0000e+00 - val_loss: 1194.8452 - val_acc: 0.0000e+00\n",
            "Epoch 139/3000\n",
            "\n",
            "Testing loss: 268.74273681640625, acc: 0.0\n",
            "\n",
            " - 112s - loss: 9.5608 - acc: 0.0000e+00 - val_loss: 1188.9896 - val_acc: 0.0000e+00\n",
            "Epoch 140/3000\n",
            "\n",
            "Testing loss: 280.19842529296875, acc: 0.0\n",
            "\n",
            " - 112s - loss: 8.4087 - acc: 0.0000e+00 - val_loss: 1229.6817 - val_acc: 0.0000e+00\n",
            "Epoch 141/3000\n",
            "\n",
            "Testing loss: 315.2608642578125, acc: 0.0\n",
            "\n",
            " - 112s - loss: 6.4267 - acc: 0.0000e+00 - val_loss: 1243.8923 - val_acc: 0.0000e+00\n",
            "Epoch 142/3000\n",
            "\n",
            "Testing loss: 283.6100158691406, acc: 0.0\n",
            "\n",
            " - 112s - loss: 4.2488 - acc: 0.0000e+00 - val_loss: 1206.6245 - val_acc: 0.0000e+00\n",
            "Epoch 143/3000\n",
            "\n",
            "Testing loss: 288.8623352050781, acc: 0.0\n",
            "\n",
            " - 111s - loss: 2.3122 - acc: 0.0000e+00 - val_loss: 1225.1471 - val_acc: 0.0000e+00\n",
            "Epoch 144/3000\n",
            "\n",
            "Testing loss: 304.3988342285156, acc: 0.0\n",
            "\n",
            " - 113s - loss: 5.6133 - acc: 0.0000e+00 - val_loss: 1242.3139 - val_acc: 0.0000e+00\n",
            "Epoch 145/3000\n",
            "\n",
            "Testing loss: 293.1201171875, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.8627 - acc: 0.0000e+00 - val_loss: 1221.5634 - val_acc: 0.0000e+00\n",
            "Epoch 146/3000\n",
            "\n",
            "Testing loss: 281.4889221191406, acc: 0.0\n",
            "\n",
            " - 113s - loss: 4.8667 - acc: 0.0000e+00 - val_loss: 1225.7196 - val_acc: 0.0000e+00\n",
            "Epoch 147/3000\n",
            "\n",
            "Testing loss: 289.23602294921875, acc: 0.0\n",
            "\n",
            " - 114s - loss: 3.2555 - acc: 0.0000e+00 - val_loss: 1209.0652 - val_acc: 0.0000e+00\n",
            "Epoch 148/3000\n",
            "\n",
            "Testing loss: 296.98248291015625, acc: 0.0\n",
            "\n",
            " - 114s - loss: 2.1779 - acc: 0.0000e+00 - val_loss: 1223.5958 - val_acc: 0.0000e+00\n",
            "Epoch 149/3000\n",
            "\n",
            "Testing loss: 291.1663818359375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 2.1237 - acc: 0.0000e+00 - val_loss: 1227.3145 - val_acc: 0.0000e+00\n",
            "Epoch 150/3000\n",
            "\n",
            "Testing loss: 298.98138427734375, acc: 0.0\n",
            "\n",
            " - 114s - loss: 4.2129 - acc: 0.0000e+00 - val_loss: 1233.9757 - val_acc: 0.0000e+00\n",
            "Epoch 151/3000\n",
            "\n",
            "Testing loss: 286.8786926269531, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.6743 - acc: 0.0000e+00 - val_loss: 1229.3860 - val_acc: 0.0000e+00\n",
            "Epoch 152/3000\n",
            "\n",
            "Testing loss: 290.9206848144531, acc: 0.0\n",
            "\n",
            " - 112s - loss: 3.7745 - acc: 0.0000e+00 - val_loss: 1220.6017 - val_acc: 0.0000e+00\n",
            "Epoch 153/3000\n",
            "\n",
            "Testing loss: 287.6298828125, acc: 0.0\n",
            "\n",
            " - 112s - loss: 3.0284 - acc: 0.0000e+00 - val_loss: 1208.5710 - val_acc: 0.0000e+00\n",
            "Epoch 154/3000\n",
            "\n",
            "Testing loss: 276.5779113769531, acc: 0.0\n",
            "\n",
            " - 112s - loss: 1.8932 - acc: 0.0000e+00 - val_loss: 1199.4999 - val_acc: 0.0000e+00\n",
            "Epoch 155/3000\n",
            "\n",
            "Testing loss: 292.7860412597656, acc: 0.0\n",
            "\n",
            " - 112s - loss: 2.3712 - acc: 0.0000e+00 - val_loss: 1230.1728 - val_acc: 0.0000e+00\n",
            "Epoch 156/3000\n",
            "\n",
            "Testing loss: 281.56353759765625, acc: 0.0\n",
            "\n",
            " - 112s - loss: 6.0500 - acc: 0.0000e+00 - val_loss: 1210.7086 - val_acc: 0.0000e+00\n",
            "Epoch 157/3000\n",
            "\n",
            "Testing loss: 269.41583251953125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 6.6594 - acc: 0.0000e+00 - val_loss: 1162.6988 - val_acc: 0.0000e+00\n",
            "Epoch 158/3000\n",
            "\n",
            "Testing loss: 307.35552978515625, acc: 0.0\n",
            "\n",
            " - 113s - loss: 5.0996 - acc: 0.0000e+00 - val_loss: 1230.8312 - val_acc: 0.0000e+00\n",
            "Epoch 159/3000\n",
            "\n",
            "Testing loss: 280.6924743652344, acc: 0.0\n",
            "\n",
            " - 113s - loss: 7.7066 - acc: 0.0000e+00 - val_loss: 1229.7164 - val_acc: 0.0000e+00\n",
            "Epoch 160/3000\n",
            "\n",
            "Testing loss: 285.1347961425781, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.6779 - acc: 0.0000e+00 - val_loss: 1199.1001 - val_acc: 0.0000e+00\n",
            "Epoch 161/3000\n",
            "\n",
            "Testing loss: 261.6541748046875, acc: 0.0\n",
            "\n",
            " - 113s - loss: 5.5310 - acc: 0.0000e+00 - val_loss: 1148.4821 - val_acc: 0.0000e+00\n",
            "Epoch 162/3000\n",
            "\n",
            "Testing loss: 265.9131164550781, acc: 0.0\n",
            "\n",
            " - 113s - loss: 6.7764 - acc: 0.0000e+00 - val_loss: 1213.9866 - val_acc: 0.0000e+00\n",
            "Epoch 163/3000\n",
            "\n",
            "Testing loss: 292.2772216796875, acc: 0.0\n",
            "\n",
            " - 114s - loss: 3.6523 - acc: 0.0000e+00 - val_loss: 1207.5270 - val_acc: 0.0000e+00\n",
            "Epoch 164/3000\n",
            "\n",
            "Testing loss: 272.2006530761719, acc: 0.0\n",
            "\n",
            " - 114s - loss: 3.0528 - acc: 0.0000e+00 - val_loss: 1179.1700 - val_acc: 0.0000e+00\n",
            "Epoch 165/3000\n",
            "\n",
            "Testing loss: 281.8534240722656, acc: 0.0\n",
            "\n",
            " - 114s - loss: 5.9346 - acc: 0.0000e+00 - val_loss: 1189.9308 - val_acc: 0.0000e+00\n",
            "Epoch 166/3000\n",
            "\n",
            "Testing loss: 283.08380126953125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 5.4403 - acc: 0.0000e+00 - val_loss: 1204.9525 - val_acc: 0.0000e+00\n",
            "Epoch 167/3000\n",
            "\n",
            "Testing loss: 285.0146484375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.0679 - acc: 0.0000e+00 - val_loss: 1223.7573 - val_acc: 0.0000e+00\n",
            "Epoch 168/3000\n",
            "\n",
            "Testing loss: 280.16937255859375, acc: 0.0\n",
            "\n",
            " - 113s - loss: 5.8401 - acc: 0.0000e+00 - val_loss: 1197.3764 - val_acc: 0.0000e+00\n",
            "Epoch 169/3000\n",
            "\n",
            "Testing loss: 271.14190673828125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 4.1186 - acc: 0.0000e+00 - val_loss: 1180.1065 - val_acc: 0.0000e+00\n",
            "Epoch 170/3000\n",
            "\n",
            "Testing loss: 289.5578308105469, acc: 0.0\n",
            "\n",
            " - 113s - loss: 2.9206 - acc: 0.0000e+00 - val_loss: 1207.9560 - val_acc: 0.0000e+00\n",
            "Epoch 171/3000\n",
            "\n",
            "Testing loss: 273.2830810546875, acc: 0.0\n",
            "\n",
            " - 112s - loss: 3.7149 - acc: 0.0000e+00 - val_loss: 1167.8158 - val_acc: 0.0000e+00\n",
            "Epoch 172/3000\n",
            "\n",
            "Testing loss: 278.9557800292969, acc: 0.0\n",
            "\n",
            " - 113s - loss: 4.6144 - acc: 0.0000e+00 - val_loss: 1215.3999 - val_acc: 0.0000e+00\n",
            "Epoch 173/3000\n",
            "\n",
            "Testing loss: 290.982421875, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.0626 - acc: 0.0000e+00 - val_loss: 1227.4795 - val_acc: 0.0000e+00\n",
            "Epoch 174/3000\n",
            "\n",
            "Testing loss: 265.48284912109375, acc: 0.0\n",
            "\n",
            " - 112s - loss: 6.6975 - acc: 0.0000e+00 - val_loss: 1171.5628 - val_acc: 0.0000e+00\n",
            "Epoch 175/3000\n",
            "\n",
            "Testing loss: 263.5548095703125, acc: 0.0\n",
            "\n",
            " - 113s - loss: 3.9927 - acc: 0.0000e+00 - val_loss: 1160.7465 - val_acc: 0.0000e+00\n",
            "Epoch 176/3000\n",
            "\n",
            "Testing loss: 268.9365539550781, acc: 0.0\n",
            "\n",
            " - 112s - loss: 6.8189 - acc: 0.0000e+00 - val_loss: 1187.1862 - val_acc: 0.0000e+00\n",
            "Epoch 177/3000\n",
            "\n",
            "Testing loss: 268.28936767578125, acc: 0.0\n",
            "\n",
            " - 112s - loss: 3.8651 - acc: 0.0000e+00 - val_loss: 1151.8984 - val_acc: 0.0000e+00\n",
            "Epoch 178/3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgK6jnJX24m0",
        "colab_type": "code",
        "outputId": "f158c43c-6890-4bc2-d6f0-6b1f6728d2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r15/15 [==============================] - 3s 202ms/sample - loss: 3217372.0000 - acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3217372.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqd1x3k3I0xm",
        "colab_type": "code",
        "outputId": "4ba1a35e-72c5-4e30-aa1d-c47a8118bc19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.predict(x_test), y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[6.564193 ],\n",
              "        [6.9798036],\n",
              "        [7.0459957],\n",
              "        [5.866261 ],\n",
              "        [7.43832  ],\n",
              "        [7.5253315],\n",
              "        [6.0166283],\n",
              "        [5.6070266],\n",
              "        [7.185611 ],\n",
              "        [6.3236146],\n",
              "        [6.9969583],\n",
              "        [6.908541 ],\n",
              "        [6.522974 ],\n",
              "        [6.6133194],\n",
              "        [7.0095625]], dtype=float32),\n",
              " array([58, 23,  8, 26, 16, 17, 12, 13,  8,  8,  5,  9, 13, 21, 12]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fetdwyfZePNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch￼\n",
        "hist.tail()\n",
        "\n",
        "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())\n",
        "# from keras import backend as K\n",
        "# K.tensorflow_backend._get_available_gpus()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7O4veRNePNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "\n",
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())\n",
        "\n",
        "# from keras import backend as K\n",
        "# K.tensorflow_backend._get_available_gpus()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}