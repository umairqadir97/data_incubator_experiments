# -*- coding: utf-8 -*-
"""
Created on Fri Jan 27 19:12:53 2017

@author: Weidi Xie

@Description: This is the file used for training, loading images, annotation, training with model.
"""

import numpy as np
import pickle
import pdb
import os
import matplotlib.pyplot as plt
from generator import ImageDataGenerator
from model import buildModel_U_net
from keras import backend as K
from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler
from scipy import misc
import scipy.ndimage as ndimage


class LossHistory(Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))

# base_path = './cells/'
data = []
anno = []

def step_decay(epoch):
    step = 16
    num =  epoch // step 
    if num % 3 == 0:
        lrate = 1e-3
    elif num % 3 == 1:
        lrate = 1e-4
    else:
        lrate = 1e-5
      # lrate = initial_lrate * 1/(1 + decay * (epoch - num * step))
    print('Learning rate for epoch {} is {}.'.format(epoch+1, lrate))
    return np.float(lrate)
  

def train_(base_path):
    base_path = './cells/cervix_images/'
    labels_path = './cells/cervix_labels/'
    data, anno = read_data(base_path, labels_path)
    anno = np.expand_dims(anno, axis = -1)
    
    #mean = np.mean(data)
    #std = np.std(data)
    
    #data_ = (data - mean) / std
    
    data_len = len(data)
    train_split = int(data_len*0.7)
    val_split = int(data_len*0.2)
    test_split = int(data_len*0.1)
    
    train_data = data[:train_split]
    train_anno = anno[:train_split]
    val_data = data[train_split : train_split+val_split]
    val_anno = anno[train_split : train_split+val_split]
    
    del data
    del anno
    
    print('-'*30)
    print('Creating and compiling the fully convolutional regression networks.')
    print('-'*30)
    
    model = buildModel_U_net(input_dim = (224,224, 3))
    model_checkpoint = ModelCheckpoint('cell_counting.hdf5', monitor='loss', save_best_only=True)
    model.summary()
    print('...Fitting model...')
    print('-'*30)
    change_lr = LearningRateScheduler(step_decay)

    datagen = ImageDataGenerator(
        featurewise_center = False,  # set input mean to 0 over the dataset
        samplewise_center = False,  # set each sample mean to 0
        featurewise_std_normalization = False,  # divide inputs by std of the dataset
        samplewise_std_normalization = False,  # divide each input by its std
        zca_whitening = False,  # apply ZCA whitening
        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range = 0.3,  # randomly shift images horizontally (fraction of total width)
        height_shift_range = 0.3,  # randomly shift images vertically (fraction of total height)
        zoom_range = 0.3,
        shear_range = 0.,
        horizontal_flip = True,  # randomly flip images
        vertical_flip = True, # randomly flip images
        fill_mode = 'constant',
        dim_ordering = 'tf')  

    # Fit the model on the batches generated by datagen.flow().
    model.fit_generator(datagen.flow(train_data,
                                     train_anno,
                                     batch_size = 16
                                     ),
                        samples_per_epoch = train_data.shape[0],
                        nb_epoch = 300,
                        callbacks = [model_checkpoint, change_lr],
                        verbose = 1, 
                        validation_data = (val_data, val_anno)
                       )
    
    model.load_weights('cell_counting.hdf5')
    A = model.predict(val_data)
    mean_diff = np.average(np.abs(np.sum(np.sum(A,1),1)-np.sum(np.sum(val_anno,1),1))) / (100.0)
    print('After training, the difference is : {} cells per image in Validation Test Set.'.format(np.abs(mean_diff)))
    # save the model
    model.save("cell_counting_model_v_1.hdf5")    
    return model


model = train_(base_path)
